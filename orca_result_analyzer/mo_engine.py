import numpy as np
from PyQt6.QtCore import QThread, pyqtSignal

# from .logger import Logger

class CubeWriter:
    @staticmethod
    def write(filepath, atoms_sym, atoms_coords, origin, vectors, data, comment=""):
        """
        Write a .cube file.
        atoms_sym: list of atomic symbols (str) or atomic numbers (int)
        atoms_coords: list/array of (x,y,z) in Angstrom
        origin: (x,y,z) of grid origin in Bohr
        vectors: 3x3 array of grid vectors in Bohr
        data: 3D numpy array of values
        """
        nx, ny, nz = data.shape
        n_atoms = len(atoms_sym)
        
        # Periodic Table for Atomic Number lookup if symbols provided
        try:
            from rdkit import Chem
            pt = Chem.GetPeriodicTable()
            to_z = lambda s: pt.GetAtomicNumber(s) if isinstance(s, str) else int(s)
        except:
            # Fallback simple map if RDKit fails (unlikely)
            to_z = lambda s: 0 if isinstance(s, str) else int(s)

        with open(filepath, 'w') as f:
            f.write(f"ORCA Analyzer Cube File: {comment}\n")
            f.write("Generated by MoleditPy ORCA Plugin\n")
            # Cube file format requires atomic coordinates in Bohr if origin/vectors are in Bohr
            # Actually, standard Cube usually defines: 
            # - Number of Atoms, Origin (X,Y,Z)
            # - NX, X-Vector
            # - NY, Y-Vector
            # - NZ, Z-Vector
            # - Atom 1: Z, Charge, X, Y, Z
            # ...
            # Volumetric Data
            
            # Note: Gaussian Cube uses Bohr for units usually.
            # Our atoms_coords are usually Angstroms from parser.
            BOHR_TO_ANG = 0.529177249
            ANG_TO_BOHR = 1.0 / BOHR_TO_ANG
            
            # Convert units to Bohr for the file
            origin_bohr = origin # Assumed passed in Bohr
            vectors_bohr = vectors # Assumed passed in Bohr
            coords_bohr = np.array(atoms_coords) * ANG_TO_BOHR
            
            f.write(f"{n_atoms:5d} {origin_bohr[0]:12.6f} {origin_bohr[1]:12.6f} {origin_bohr[2]:12.6f}\n")
            f.write(f"{nx:5d} {vectors_bohr[0,0]:12.6f} {vectors_bohr[0,1]:12.6f} {vectors_bohr[0,2]:12.6f}\n")
            f.write(f"{ny:5d} {vectors_bohr[1,0]:12.6f} {vectors_bohr[1,1]:12.6f} {vectors_bohr[1,2]:12.6f}\n")
            f.write(f"{nz:5d} {vectors_bohr[2,0]:12.6f} {vectors_bohr[2,1]:12.6f} {vectors_bohr[2,2]:12.6f}\n")
            
            for i in range(n_atoms):
                z_no = to_z(atoms_sym[i])
                # Cube format: Z, Charge(float), X, Y, Z (Bohr)
                f.write(f"{z_no:5d} {float(z_no):12.6f} {coords_bohr[i][0]:12.6f} {coords_bohr[i][1]:12.6f} {coords_bohr[i][2]:12.6f}\n")
            
            vals = data.flatten()
            for i, v in enumerate(vals):
                f.write(f"{v:13.5E}")
                if (i + 1) % 6 == 0:
                    f.write("\n")
            if len(vals) % 6 != 0:
                f.write("\n")

class BasisSetEngine:
    """
    Evaluates GTO-based Basis Sets on a grid.
    Adapted for ORCA General Basis Format.
    """
    def __init__(self, shells):
        """
        shells: list of dicts defining the basis set.
        Each shell: {
            'type': int (0=S, 1=P, 2=D, 3=F...), 
            'center': [x, y, z] (BOHR or Angstrom? Assuming Input is BOHR to match internal logic),
            'exps': np.array([...]), 
            'coeffs': np.array([...]) 
        }
        """
        # self.logger = Logger.get_logger("BasisSetEngine")
        self.shells = shells
        self.n_basis = 0
        self._prepare_definitions()
        self._precompute_shells()

    def _normalization_prefactor(self, alpha, l, m, n):
        L = l + m + n
        fact = {0: 1, 1: 1, 2: 2, 3: 6, 4: 24, 5: 120}
        fact2 = {0: 1, 1: 2, 2: 24, 3: 720, 4: 40320, 5: 3628800} 
        
        num = (8 * alpha)**L * fact[l] * fact[m] * fact[n]
        den = fact2[l] * fact2[m] * fact2[n]
        return ((2 * alpha / np.pi)**0.75) * np.sqrt(num / den)

    def _prepare_definitions(self):
        # Cartesian Definitions (1:1)
        cart_s = [ [(1.0, (0,0,0))] ] # S
        # ORCA P-order: pz, px, py (based on benzene-ene.out observation)
        # Engine expects: [0] -> pz, [1] -> px, [2] -> py
        # Definitions must map these to (0,0,1), (1,0,0), (0,1,0)
        cart_p = [ [(1.0, (0,0,1))], [(1.0, (1,0,0))], [(1.0, (0,1,0))] ] # Pz, Px, Py
        
        # d shells
        # ORCA usually uses Spherical Harmonics for d/f in standard output unless explicitly Cartesian.
        # But "BASIS SET IN INPUT FORMAT" defines primitives. The *contracted* layout depends on the calculation.
        # IMPORTANT: ORCA coefficients (MOs) correspond to the order used in calculation.
        # Assuming Spherical (5D, 7F) is standard for ORCA.
        
        # Spherical D (5 components)
        # Order check needed: ORCA usually d0, d+1, d-1, d+2, d-2
        # d0 (3z2-r2), d1(xz), d-1(yz), d2(x2-y2), d-2(xy)
        # Verify normalization.
        
        sph_d = [
            [ (-0.5, (2,0,0)), (-0.5, (0,2,0)), (1.0, (0,0,2)) ], # d(3z^2-r^2) -> 3zz - (xx+yy+zz) = 2zz-xx-yy
            [ (1.0, (1,0,1)) ], # d(xz)
            [ (1.0, (0,1,1)) ], # d(yz)
            [ (0.866025, (2,0,0)), (-0.866025, (0,2,0)) ], # d(x^2-y^2) ~ sqrt(3)/2
            [ (1.0, (1,1,0)) ]  # d(xy)
        ]
        
        # Spherical F (7 components)
        f0_n = 0.240654; f1_n = 0.281160; f2_n = 0.866025; f3_n = 0.369693
        sph_f = [
            [ (2.0*f0_n, (0,0,3)), (-3.0*f0_n, (2,0,1)), (-3.0*f0_n, (0,2,1)) ], # z(5z2-3r2)
            [ (4.0*f1_n, (1,0,2)), (-1.0*f1_n, (3,0,0)), (-1.0*f1_n, (1,2,0)) ], # x(5z2-r2)
            [ (4.0*f1_n, (0,1,2)), (-1.0*f1_n, (2,1,0)), (-1.0*f1_n, (0,3,0)) ], # y(5z2-r2)
            [ (1.0*f2_n, (2,0,1)), (-1.0*f2_n, (0,2,1)) ], # z(x2-y2)
            [ (1.0, (1,1,1)) ], # xyz
            [ (1.0*f3_n, (3,0,0)), (-3.0*f3_n, (1,2,0)) ], # x(x2-3y2)
            [ (3.0*f3_n, (2,1,0)), (-1.0*f3_n, (0,3,0)) ]  # y(3x2-y2)
        ]

        self.basis_definitions = {
            0: cart_s,
            1: cart_p,
            2: sph_d,
            3: sph_f,
            4: [] # G-shells (placeholder - not yet implemented)
        }
    
    def _precompute_shells(self):
        """Prepare shell data for fast evaluation"""
        current_idx = 0
        for sh in self.shells:
            l_type = sh['type']
            defs = self.basis_definitions.get(l_type)
            if not defs:
                # Fallback or error?
                # self.logger.warning(f"Unsupported shell type {l_type}")
                print(f"Warning: Unsupported shell type {l_type}")
                sh['basis_data'] = []
                continue

            sh['defs'] = defs
            
            func_norm_coeffs = []
            for basis_func_def in defs:
                comps_data = []
                for weight, (l, m, n) in basis_func_def:
                     prim_norms = np.array([self._normalization_prefactor(a, l, m, n) for a in sh['exps']])
                     # Combined Coeff = Input_Coeff * Normalization * Weight
                     comp_coeffs = sh['coeffs'] * prim_norms * weight
                     
                     comps_data.append({
                         'l': l, 'm': m, 'n': n,
                         'coeffs': comp_coeffs
                     })
                func_norm_coeffs.append(comps_data)
            
            sh['basis_data'] = func_norm_coeffs
            sh['start_idx'] = current_idx
            current_idx += len(defs)
            
        self.n_basis = current_idx

    def evaluate_mo_on_grid(self, mo_idx, grid_coords, mo_coeffs_all):
        """
        Evaluate MO on grid (Vectorized Implementation).
        mo_coeffs_all: 1D array of all MO coefficients (must match n_basis)
        grid_coords: (N, 3) array in BOHR
        """
        my_coeffs = mo_coeffs_all
        if len(my_coeffs) < self.n_basis:
             raise ValueError(f"Not enough coefficients. Needed {self.n_basis}, got {len(my_coeffs)}")
        
        phi_mo = np.zeros(grid_coords.shape[0])
        
        for sh in self.shells:
            if 'basis_data' not in sh or not sh['basis_data']: continue
            
            # 1. Calculate Radial Part for this Shell
            # grid_coords is (N,3), center is (3,)
            r_vec = grid_coords - sh['center']
            r2 = np.sum(r_vec**2, axis=1)
            
            # Evaluate Exponents: exp(-alpha * r2)
            # sh['exps'] is (K,), r2 is (N,) -> E is (K, N)
            E = np.exp(-np.outer(sh['exps'], r2)) 
            
            # 2. Iterate Components (S, P, D...)
            start = sh['start_idx']
            
            # Optimization: Group calculations by unique angular momentum sets if possible,
            # but current structure is Shell -> [BasisFunc1, BasisFunc2...]
            # where BasisFunc1 -> [Component1, Component2...]
            
            for b_i, basis_func_data in enumerate(sh['basis_data']):
                c_mo = my_coeffs[start + b_i]
                if abs(c_mo) < 1e-9: continue
                
                # Each basis function is a sum of components (e.g. contracted Gaussians with specific L, M, N)
                # But typically for standard basis sets, one "basis function" (like Px) 
                # has ONE component list (e.g. 3 primitives all with l=1,m=0,n=0).
                # SP shells might be different but handled as separate shells in prep.
                
                # Vectorize over components if multiple?
                # Usually basis_func_data has 1 component (e.g. Px) or few.
                
                val_accum = np.zeros(grid_coords.shape[0])
                
                for comp in basis_func_data:
                    l, m, n = comp['l'], comp['m'], comp['n']
                    coeffs_prim = comp['coeffs'] # (K,)
                    
                    # Radial contraction: sum( c_i * exp(-a_i * r2) )
                    # This is dot product (K) . (K, N) -> (N,)
                    contracted_radial = np.dot(coeffs_prim, E)
                    
                    # Angular part
                    # Check if l,m,n form a trivial case (0,0,0) -> S-orbital -> ang_val = 1.0
                    if l == 0 and m == 0 and n == 0:
                         val_accum += contracted_radial
                    else:
                        ang_val = np.ones(grid_coords.shape[0])
                        if l > 0: ang_val *= r_vec[:, 0]**l
                        if m > 0: ang_val *= r_vec[:, 1]**m
                        if n > 0: ang_val *= r_vec[:, 2]**n
                        val_accum += ang_val * contracted_radial
                
                phi_mo += c_mo * val_accum
                
        return phi_mo


class CalcWorker(QThread):
    progress_sig = pyqtSignal(int)
    finished_sig = pyqtSignal(bool, str)

    def __init__(self, engine, mo_idx, n_points, margin, atoms_sym, atoms_coords, mo_coeffs, output_path):
        super().__init__()
        self.engine = engine
        self.mo_idx = mo_idx
        self.n_points = n_points # grid points per axis
        self.margin = margin # in Angstrom
        self.atoms_sym = atoms_sym
        self.atoms_coords = atoms_coords # Angstrom
        self.mo_coeffs = mo_coeffs
        self.output_path = output_path
        self._is_cancelled = False
        
    def run(self):
        try:
            BOHR_TO_ANG = 0.529177249
            ANG_TO_BOHR = 1.0 / BOHR_TO_ANG
            
            # Define Grid in BOHR (Engine expects Bohr)
            coords_bohr = np.array(self.atoms_coords) * ANG_TO_BOHR
            margin_bohr = self.margin * ANG_TO_BOHR
            
            min_c = np.min(coords_bohr, axis=0) - margin_bohr
            max_c = np.max(coords_bohr, axis=0) + margin_bohr
            span = max_c - min_c
            
            nx = ny = nz = self.n_points
            dx = span[0] / (nx - 1)
            dy = span[1] / (ny - 1)
            dz = span[2] / (nz - 1)
            
            x = np.linspace(min_c[0], max_c[0], nx)
            y = np.linspace(min_c[1], max_c[1], ny)
            z = np.linspace(min_c[2], max_c[2], nz)
            
            X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
            grid_points = np.column_stack([X.ravel(), Y.ravel(), Z.ravel()])
            
            n_total = grid_points.shape[0]
            chunk_size = 50000
            result_flat = np.zeros(n_total)
            
            for i, start in enumerate(range(0, n_total, chunk_size)):
                if self._is_cancelled: return
                end = min(start + chunk_size, n_total)
                chunk_pts = grid_points[start:end]
                
                val = self.engine.evaluate_mo_on_grid(self.mo_idx, chunk_pts, self.mo_coeffs)
                result_flat[start:end] = val
                
                pct = int((end/n_total)*100)
                self.progress_sig.emit(pct)
                
            # Write Cube
            vol_data = result_flat.reshape(nx, ny, nz)
            vectors = np.diag([dx, dy, dz])
            
            CubeWriter.write(
                self.output_path, 
                self.atoms_sym, 
                self.atoms_coords, 
                min_c, 
                vectors, 
                vol_data, 
                comment=f"MO {self.mo_idx + 1}"
            )
            
            self.finished_sig.emit(True, self.output_path)
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            self.finished_sig.emit(False, str(e))
